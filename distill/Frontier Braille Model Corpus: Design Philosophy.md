# Frontier Braille Model Corpus: Design Philosophy

## 1. Core Objective

The **Frontier Braille Model Corpus** is designed to validate whether a dynamic-vocabulary, contraction-learning language model learns **operators and structure** rather than memorizing surface strings. This is fundamentally different from traditional language modeling corpora, which optimize for coverage and perplexity.

## 2. Design Principles

### 2.1. No Genre Monoculture

Traditional corpora often suffer from genre bias, where a single source or register dominates the dataset. This corpus explicitly avoids this by:

- Ensuring no single source dominates more than 10–15% of tokens
- Mixing multiple structural regimes (dialogues, procedures, logical text, temporal narratives, lists)
- Combining synthetic and natural language data
- Including multilingual content with different morphological systems

### 2.2. Structure Over Semantics

This corpus prioritizes **morphology, scope, agreement, and composition** over factual knowledge. The model should learn how language is structured, not what facts are true. This means:

- Synthetic morphology samples are designed to expose morphological rules
- English stressors focus on structural phenomena (pronoun reference, conditional scope, temporal ordering)
- Adversarial perturbations destroy n-gram shortcuts that rely on surface form

### 2.3. Adversarial Splits

Every major structure in the corpus has:

- **Seen tokens**: Examples the model encounters during training
- **Unseen combinations**: Feature combinations or structures held out from training to test generalization

This enables rigorous evaluation of whether the model has learned generalizable rules or merely memorized surface patterns.

### 2.4. Evaluation-Driven

The corpus is designed to support specific evaluation protocols:

- **Held-out constructions**: Measure loss on unseen feature combinations
- **Macro ablation tests**: Remove learned contractions and measure impact
- **Surface re-encoding tests**: Measure loss on perturbed variants

## 3. Corpus Components

### 3.1. Synthetic Morphology Engine

The synthetic morphology engine generates words from roots and feature bundles using four distinct morphological regimes:

#### Concatenative Morphology
- Structure: prefix + root + suffix
- Example: un-happy-ness
- Test goal: Verify the model learns prefix/suffix attachment and composition

#### Agglutinative Morphology
- Structure: long linear stacks of transparent morphemes
- Example (Turkish): ev-ler-in-de (house-PL-GEN-LOC)
- Test goal: Verify the model learns consistent morpheme order and stacking

#### Fusional Morphology
- Structure: merged feature realizations in single allomorph
- Example (Spanish): habl-o, habl-as, habl-amos
- Test goal: Verify the model learns feature fusion and allomorphic variation

#### Templatic Morphology
- Structure: consonantal root + vowel template (non-concatenative)
- Example (Arabic): k-t-b with template CaCaC → katab
- Test goal: Verify the model learns non-local binding and template-based composition

**Critical requirement**: Specific feature combinations are held out at train time and tested on unseen combinations using the same roots. This forces the model to learn the underlying morphological rules rather than memorize surface forms.

### 3.2. Natural Language Stressors

English text is curated across five distinct structural regimes:

#### Dialogues
- Turn-taking with pronoun reference and ellipsis
- Tests: discourse structure, anaphora resolution

#### Instructions/Procedures
- Imperative mood, ordered steps, conditional branching
- Tests: procedural ordering, conditional scope

#### Logical/Conditional Text
- If/unless, negation scope, counterfactuals
- Tests: logical operators, scope interactions

#### Temporal Reordering
- Non-linear narratives, flashbacks, before/after inversions
- Tests: temporal structure independent of surface order

#### Lists and Tables
- Parallel structure, implicit grouping
- Tests: parallel structure recognition, implicit grouping

For each category, the corpus includes paraphrase variants that alter surface markers while preserving structure.

### 3.3. Minimal Multilingual Injection

The corpus includes a single morphologically rich language (Turkish) with parallel meaning to English examples. This forces the model to discover different contraction regimes without explicit language tags:

- Turkish examples use agglutinative morphology (e.g., ev-ler-in-de)
- English examples use different structural patterns
- No language tags are provided during training

This tests whether the model can discover language-specific contraction patterns through structure alone.

### 3.4. Surface Perturbation Layer

Adversarial samples are generated by applying controlled perturbations to existing samples:

#### Tokenization Perturbation
- Merge/split words while preserving meaning
- Tests: robustness to token boundary changes

#### Punctuation Perturbation
- Alter punctuation while preserving structure
- Tests: structure learning independent of punctuation

#### Entity Perturbation
- Rename entities consistently
- Tests: structure learning independent of entity identity

#### Phrase Order Perturbation
- Reorder phrases while preserving equivalence
- Tests: meaning learning independent of surface order

## 4. Corpus Size and Composition

The corpus is designed to be **small but high-quality**, with the following target composition:

- **Synthetic morphology**: 20–30%
- **English structural stressors**: 40–50%
- **Multilingual/templatic**: 10–15%
- **Perturbed/adversarial variants**: 10–15%

Total size can be tens of millions of tokens. **Quality > quantity**.

## 5. Explicit Anti-Goals

The following practices are explicitly avoided:

- **No blind web scraping**: Uncontrolled web data introduces genre monoculture and factual bias
- **No large factual corpora**: Wikipedia, books, and similar sources optimize for coverage, not structure
- **No perplexity optimization**: Perplexity is not a meaningful metric for structural learning
- **No pre-tokenization or pre-contraction**: The model must learn tokenization and contraction from raw input
- **No leakage of held-out constructions**: Held-out samples must remain completely separate from training

## 6. Success Criteria

This corpus is successful if it enables the measurement of:

1. **Generalization**: Learned contractions generalize across roots and survive macro ablation
2. **Robustness**: Loss stays low on unseen feature combinations and surface-perturbed variants
3. **Natural compression**: Compression plateaus naturally without vocabulary explosion or collapse

If the corpus cannot falsify the hypothesis that the model is merely memorizing, it has failed.

## 7. Metadata and Evaluation

Each sample includes metadata strictly for evaluation purposes:

- **source_category**: Primary source (synthetic_morphology, english_stressor, multilingual, adversarial)
- **structural_type**: Specific type for evaluation
- **held_out**: Whether the sample is part of held-out evaluation
- **has_variants**: Whether surface variants exist
- **latent_structure**: Structural annotation (never fed to model)

The `evaluation.py` script provides tools for:

- **Macro masking**: Mask learned contractions and measure loss increase
- **Held-out composition**: Measure loss on unseen feature combinations
- **Surface re-encoding**: Measure loss on perturbed variants
- **Ablation tests**: Remove specific morpheme types and measure impact

## 8. Usage Philosophy

This corpus is designed to make it **easy to prove the model is wrong** and **hard to prove it is right**. If a model survives this corpus, the claims that it has learned structure (rather than memorized) are worth taking seriously.

The corpus should be used as follows:

1. Train the model on the training split
2. Evaluate on held-out, variant, and adversarial splits
3. Use the evaluation protocol to measure whether the model has learned structure
4. If the model fails any of the tests, investigate why
5. If the model passes all tests, the claims are credible

