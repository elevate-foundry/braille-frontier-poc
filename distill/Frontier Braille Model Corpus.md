'''
# Frontier Braille Model Corpus

**Version**: 1.0.0
**Author**: Manus AI

## 1. Introduction

The **Frontier Braille Model Corpus** is a targeted, adversarial training corpus designed to validate whether a dynamic-vocabulary, contraction-learning language model is learning **operators and structure** rather than memorizing surface strings. This corpus is not about scale but about controlled diversity, held-out generalization, and morphological stress tests. It is built exclusively for machine learning training, specifically for models that aim to discover structure and operators in an 8-dot Braille symbol space.

This document provides a comprehensive overview of the corpus architecture, generation process, and evaluation protocol.

## 2. Corpus Architecture

The corpus is designed around four key components, each targeting a specific aspect of structural learning.

| Component                      | Description                                                                                                                              | Purpose                                                                    |
| ------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------- |
| **Synthetic Morphology Engine**  | Generates text from roots and feature bundles using concatenative, agglutinative, fusional, and templatic morphology.                      | Tests the model's ability to learn and generalize morphological rules.       |
| **Natural Language Stressors** | Curated English text across distinct structural regimes (dialogues, instructions, logical text, temporal reordering, and lists).           | Tests the model's understanding of scope, agreement, and composition.      |
| **Minimal Multilingual Injection** | Includes a morphologically rich language (Turkish) with parallel meaning to English examples.                                            | Forces the discovery of different contraction regimes without supervision. |
| **Surface Perturbation Layer**   | Generates equivalent re-encodings of a subset of the corpus with altered token boundaries, punctuation, entities, and phrase order. | Destroys na√Øve n-gram shortcuts and tests for robust structural learning.  |

### 2.1. 8-Dot Braille Encoding

All text in the corpus is encoded into an 8-dot Braille symbol space, which provides 256 unique symbols. This serves as the foundational multimodal substrate for the model. The mapping from characters to Braille cells is deterministic, using a hash-based approach to ensure reproducibility.

## 3. Corpus Generation

The corpus is generated by the `corpus_generator.py` script, which orchestrates the different components to produce a balanced and structured dataset. The generation process is deterministic and seedable, ensuring that the exact same corpus can be reproduced.

### 3.1. Corpus Splits

The generator outputs the corpus in several JSONL files, each representing a specific split for training and evaluation:

-   `train.jsonl`: The main training set, containing all samples that are not held-out or adversarial.
-   `eval_held_out.jsonl`: An evaluation set containing samples with feature combinations that were not seen during training.
-   `eval_variants.jsonl`: An evaluation set for surface re-encoding tests, containing samples with known surface variations.
-   `eval_adversarial.jsonl`: An evaluation set containing perturbed samples designed to test the model's robustness.

### 3.2. Metadata Schema

Each sample in the corpus is accompanied by a rich set of metadata, which is strictly for evaluation purposes and should not be fed to the model. The `corpus_schema.json` file provides a detailed description of the metadata structure, including the source category, structural type, and whether the sample is part of a held-out split.

## 4. Evaluation Protocol

The success of a model trained on this corpus is measured by its ability to demonstrate true structural understanding. The `evaluation.py` script provides tools to perform the following tests:

-   **Macro Masking**: This test involves masking learned contractions and measuring the resulting increase in loss. A predictable increase suggests that the model has learned meaningful operators.
-   **Held-Out Composition**: This test measures the model's performance on unseen feature combinations. Low loss on these samples indicates that the model has generalized the underlying morphological rules.
-   **Surface Re-encoding**: This test compares the model's performance on original samples versus their perturbed variants. Stable performance across perturbations suggests that the model has learned the structure independent of the surface form.

## 5. How to Use

1.  **Generate the Corpus**: Run the `generate_corpus.py` script to create the dataset. You can customize the total number of samples and the random seed.

    ```shell
    python3 generate_corpus.py --total-samples 10000 --output-dir ./corpus
    ```

2.  **Train the Model**: Use the `train.jsonl` file to train your language model. The input to the model should be the `braille_encoding` field.

3.  **Evaluate the Model**: Use the evaluation splits (`eval_held_out.jsonl`, `eval_variants.jsonl`, `eval_adversarial.jsonl`) and the `evaluation.py` script to assess your model's performance on the key structural learning tasks.

    ```shell
    python3 evaluation.py ./corpus/corpus_combined.jsonl --output-report report.md
    ```

## 6. Success Criteria

This corpus is successful if it enables the measurement of the following:

-   Whether learned contractions generalize across roots and survive macro ablation.
-   Whether the model maintains low loss on unseen feature combinations and surface-perturbed variants.
-   Whether compression plateaus naturally without vocabulary explosion or collapse.

If the corpus cannot falsify the hypothesis that the model is merely memorizing, it has failed in its purpose.
'''
