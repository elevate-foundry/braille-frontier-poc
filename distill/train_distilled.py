"""
Train Braille Frontier Model on distilled data.

This script trains on data generated by a large teacher model,
effectively distilling the teacher's knowledge into the compact Braille model.

Usage:
    modal run distill/train_distilled.py --data data/braille_train.pt
"""

import modal

app = modal.App("braille-distill")

image = modal.Image.debian_slim(python_version="3.11").pip_install(
    "torch>=2.0.0",
    "numpy",
)

volume = modal.Volume.from_name("braille-checkpoints", create_if_missing=True)
data_volume = modal.Volume.from_name("braille-training-data", create_if_missing=True)


@app.function(
    image=image,
    gpu="A100",
    timeout=7200,  # 2 hours
    volumes={
        "/checkpoints": volume,
        "/data": data_volume,
    },
)
def train_distilled(data_path: str = "/data/braille_train.pt", epochs: int = 50):
    """Train on distilled data from large model."""
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.utils.data import TensorDataset, DataLoader
    import time
    
    # =========================================================================
    # MODEL DEFINITION (same as modal_train.py)
    # =========================================================================
    
    BRAILLE_BASE = 0x2800
    PAD_ID = 0
    BOS_ID = 256
    EOS_ID = 257
    UNK_ID = 258
    VOCAB_SIZE = 259
    
    def build_mask_table(vocab_size=VOCAB_SIZE):
        table = torch.zeros(vocab_size, 8, dtype=torch.float32)
        for i in range(256):
            mask = torch.tensor([(i >> bit) & 1 for bit in range(8)], dtype=torch.float32)
            table[i] = mask
        return table
    
    class RMSNorm(nn.Module):
        def __init__(self, dim, eps=1e-6):
            super().__init__()
            self.eps = eps
            self.weight = nn.Parameter(torch.ones(dim))
        
        def forward(self, x):
            rms = torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)
            return x * rms * self.weight
    
    class BrailleInfinityEmbedding(nn.Module):
        def __init__(self, vocab_size=VOCAB_SIZE, d_model=512, gate_init=1.0):
            super().__init__()
            self.d_model = d_model
            self.residual = nn.Embedding(vocab_size, d_model)
            nn.init.normal_(self.residual.weight, std=0.02)
            self.geom_proj = nn.Linear(8, d_model, bias=False)
            self.gate = nn.Embedding(vocab_size, 1)
            nn.init.constant_(self.gate.weight, gate_init)
            self.register_buffer("mask_table", build_mask_table(vocab_size))
        
        def forward(self, token_ids):
            masks = self.mask_table[token_ids]
            geom = self.geom_proj(masks)
            res = self.residual(token_ids)
            g = torch.sigmoid(self.gate(token_ids))
            return res + g * geom
    
    class Attention(nn.Module):
        def __init__(self, d_model, n_heads, dropout=0.0):
            super().__init__()
            self.n_heads = n_heads
            self.head_dim = d_model // n_heads
            self.wq = nn.Linear(d_model, d_model, bias=False)
            self.wk = nn.Linear(d_model, d_model, bias=False)
            self.wv = nn.Linear(d_model, d_model, bias=False)
            self.wo = nn.Linear(d_model, d_model, bias=False)
            self.dropout = nn.Dropout(dropout)
        
        def forward(self, x, mask=None):
            B, T, D = x.shape
            q = self.wq(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)
            k = self.wk(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)
            v = self.wv(x).view(B, T, self.n_heads, self.head_dim).transpose(1, 2)
            attn_out = F.scaled_dot_product_attention(q, k, v, is_causal=True)
            attn_out = attn_out.transpose(1, 2).contiguous().view(B, T, D)
            return self.wo(attn_out)
    
    class FeedForward(nn.Module):
        def __init__(self, d_model, d_ff=None, dropout=0.0):
            super().__init__()
            d_ff = d_ff or d_model * 4
            self.w1 = nn.Linear(d_model, d_ff, bias=False)
            self.w2 = nn.Linear(d_ff, d_model, bias=False)
            self.w3 = nn.Linear(d_model, d_ff, bias=False)
            self.dropout = nn.Dropout(dropout)
        
        def forward(self, x):
            return self.dropout(self.w2(F.silu(self.w1(x)) * self.w3(x)))
    
    class TransformerBlock(nn.Module):
        def __init__(self, d_model, n_heads, d_ff=None, dropout=0.0):
            super().__init__()
            self.attn_norm = RMSNorm(d_model)
            self.attn = Attention(d_model, n_heads, dropout)
            self.ff_norm = RMSNorm(d_model)
            self.ff = FeedForward(d_model, d_ff, dropout)
        
        def forward(self, x, mask=None):
            x = x + self.attn(self.attn_norm(x), mask)
            x = x + self.ff(self.ff_norm(x))
            return x
    
    class BrailleFrontierModel(nn.Module):
        def __init__(self, vocab_size=VOCAB_SIZE, d_model=512, n_layers=12, n_heads=8, dropout=0.1):
            super().__init__()
            self.embed = BrailleInfinityEmbedding(vocab_size, d_model)
            self.embed_dropout = nn.Dropout(dropout)
            self.layers = nn.ModuleList([
                TransformerBlock(d_model, n_heads, None, dropout)
                for _ in range(n_layers)
            ])
            self.norm = RMSNorm(d_model)
            self.head = nn.Linear(d_model, vocab_size, bias=False)
            self.head.weight = self.embed.residual.weight
        
        def forward(self, input_ids, mask=None):
            x = self.embed(input_ids)
            x = self.embed_dropout(x)
            for layer in self.layers:
                x = layer(x, mask)
            x = self.norm(x)
            return self.head(x)
        
        def count_parameters(self):
            return sum(p.numel() for p in self.parameters() if p.requires_grad)
    
    # =========================================================================
    # TRAINING
    # =========================================================================
    
    print("=" * 60)
    print("BRAILLE FRONTIER - DISTILLATION TRAINING")
    print("=" * 60)
    
    device = torch.device("cuda")
    print(f"Device: {torch.cuda.get_device_name(0)}")
    
    # Load data
    print(f"\nLoading data from {data_path}...")
    data = torch.load(data_path)
    input_ids = data["input_ids"]
    target_ids = data["target_ids"]
    
    print(f"  Sequences: {input_ids.shape[0]:,}")
    print(f"  Context length: {input_ids.shape[1]}")
    print(f"  Total tokens: {input_ids.numel():,}")
    
    dataset = TensorDataset(input_ids, target_ids)
    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)
    
    # Model
    model = BrailleFrontierModel(
        d_model=512,
        n_layers=12,
        n_heads=8,
        dropout=0.1,
    ).to(device)
    model = torch.compile(model)
    
    print(f"\nModel parameters: {model.count_parameters():,}")
    
    # Optimizer with cosine schedule
    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01, fused=True)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    scaler = torch.amp.GradScaler('cuda')
    
    # Training loop
    print(f"\nTraining for {epochs} epochs...")
    print("-" * 60)
    
    total_start = time.time()
    best_loss = float('inf')
    
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0
        epoch_start = time.time()
        
        for input_batch, target_batch in dataloader:
            input_batch = input_batch.to(device)
            target_batch = target_batch.to(device)
            
            with torch.amp.autocast('cuda', dtype=torch.bfloat16):
                logits = model(input_batch)
                loss = F.cross_entropy(
                    logits.view(-1, VOCAB_SIZE),
                    target_batch.view(-1),
                    ignore_index=PAD_ID,
                )
            
            optimizer.zero_grad()
            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            scaler.step(optimizer)
            scaler.update()
            
            epoch_loss += loss.item()
        
        scheduler.step()
        epoch_time = time.time() - epoch_start
        avg_loss = epoch_loss / len(dataloader)
        lr = scheduler.get_last_lr()[0]
        
        print(f"Epoch {epoch+1:3d}/{epochs} | Loss: {avg_loss:.4f} | LR: {lr:.2e} | Time: {epoch_time:.1f}s")
        
        # Save best model
        if avg_loss < best_loss:
            best_loss = avg_loss
            torch.save(model.state_dict(), "/checkpoints/model_distilled_best.pt")
        
        # Checkpoint every 10 epochs
        if (epoch + 1) % 10 == 0:
            torch.save(model.state_dict(), f"/checkpoints/model_distilled_epoch_{epoch+1}.pt")
            volume.commit()
    
    total_time = time.time() - total_start
    print("-" * 60)
    print(f"Total training time: {total_time/60:.1f} minutes")
    print(f"Best loss: {best_loss:.4f}")
    
    # Save final model
    torch.save(model.state_dict(), "/checkpoints/model_distilled_final.pt")
    volume.commit()
    
    print(f"\nPeak GPU memory: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB")
    
    return {"best_loss": best_loss, "time": total_time}


@app.local_entrypoint()
def main(data: str = "/data/braille_train.pt", epochs: int = 50):
    print("Starting distillation training on A100...")
    result = train_distilled.remote(data, epochs)
    print(f"\nTraining complete!")
    print(f"Best loss: {result['best_loss']:.4f}")
    print(f"Total time: {result['time']/60:.1f} minutes")
